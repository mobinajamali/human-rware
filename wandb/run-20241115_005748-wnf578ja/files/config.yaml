_wandb:
    value:
        cli_version: 0.18.5
        m: []
        python_version: 3.10.15
        t:
            "1":
                - 1
                - 5
                - 52
                - 53
                - 55
            "2":
                - 1
                - 5
                - 52
                - 53
                - 55
            "3":
                - 13
                - 16
                - 23
                - 55
                - 61
            "4": 3.10.15
            "5": 0.18.5
            "8":
                - 5
            "12": 0.18.5
            "13": linux-aarch64
action_selector:
    value: soft_policies
add_value_last_step:
    value: true
agent:
    value: rnn
agent_help_mode:
    value: true
agent_output_type:
    value: pi_logits
batch_size:
    value: 10
batch_size_run:
    value: 10
buffer_cpu_only:
    value: true
buffer_size:
    value: 10
checkpoint_path:
    value: ""
common_reward:
    value: false
critic_type:
    value: cv_critic
entropy_coef:
    value: 0.001
env:
    value: gymma
env_args:
    value:
        key: rware:rware-tiny-4ag-v2
        pretrained_wrapper: null
        seed: 42
        time_limit: 50
epochs:
    value: 4
eps_clip:
    value: 0.2
evaluate:
    value: false
gamma:
    value: 0.99
grad_norm_clip:
    value: 10
help_prob:
    value: 1
helper_time:
    value: 30
hidden_dim:
    value: 128
hypergroup:
    value: null
label:
    value: default_label
lambd:
    value: 1
learner:
    value: ppo_learner
learner_log_interval:
    value: 10000
load_step:
    value: 0
local_results_path:
    value: results
log_interval:
    value: 50000
lr:
    value: 0.0003
mac:
    value: basic_mac
mask_before_softmax:
    value: true
name:
    value: mappo
obs_agent_id:
    value: true
obs_individual_obs:
    value: false
obs_last_action:
    value: false
optim_alpha:
    value: 0.99
optim_eps:
    value: 1e-05
p_dec:
    value: 1000000
p_min:
    value: 0.2
q_nstep:
    value: 5
render:
    value: false
repeat_id:
    value: 1
reward_scalarisation:
    value: sum
runner:
    value: parallel
runner_log_interval:
    value: 10000
save_model:
    value: true
save_model_interval:
    value: 100000
save_replay:
    value: false
seed:
    value: 42
standardise_returns:
    value: false
standardise_rewards:
    value: true
t_max:
    value: 3000000
target_update_interval_or_tau:
    value: 0.01
test_greedy:
    value: true
test_interval:
    value: 50000
test_nepisode:
    value: 100
use_cuda:
    value: false
use_rnn:
    value: true
use_tensorboard:
    value: false
use_wandb:
    value: true
wandb_mode:
    value: online
wandb_project:
    value: human-in-the-loop
wandb_save_model:
    value: true
wandb_team:
    value: university_of_calgary
