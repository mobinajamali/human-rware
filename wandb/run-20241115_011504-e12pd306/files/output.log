[INFO 01:15:04] my_main *******************
[INFO 01:15:04] my_main WANDB RUN ID:
[INFO 01:15:04] my_main e12pd306
[INFO 01:15:04] my_main *******************
[INFO 01:15:04] my_main Beginning training for 3000000 timesteps
agent help is true at t: 0, t_env: 0
/home/ubuntu/PERSONAL-DIR/UOA-NEW/final/human-rware/src/controllers/basic_controller.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = th.load(self.path)
agent help is true at t: 30, t_env: 0
[INFO 01:15:05] my_main t_env: 500 / 3000000
[INFO 01:15:05] my_main Estimated time left: 23 seconds. Time passed: 0 seconds
agent help is true at t: 0, t_env: 500
agent help is true at t: 30, t_env: 500
agent help is true at t: 0, t_env: 500
agent help is true at t: 30, t_env: 500
agent help is true at t: 0, t_env: 500
agent help is true at t: 30, t_env: 500
agent help is true at t: 0, t_env: 500
agent help is true at t: 30, t_env: 500
agent help is true at t: 0, t_env: 500
agent help is true at t: 30, t_env: 500
agent help is true at t: 0, t_env: 500
agent help is true at t: 30, t_env: 500
agent help is true at t: 0, t_env: 500
agent help is true at t: 30, t_env: 500
agent help is true at t: 0, t_env: 500
agent help is true at t: 30, t_env: 500
agent help is true at t: 0, t_env: 500
agent help is true at t: 30, t_env: 500
agent help is true at t: 0, t_env: 500
agent help is true at t: 30, t_env: 500
[INFO 01:15:06] my_main Saving models to results/models/mappo_seed42_rware_rware-tiny-4ag-v2_2024-11-15 01_15_03.499275
agent help is true at t: 0, t_env: 500
agent help is true at t: 30, t_env: 500
agent help is true at t: 0, t_env: 1000
agent help is true at t: 30, t_env: 1000
agent help is true at t: 0, t_env: 1500
agent help is true at t: 30, t_env: 1500
agent help is true at t: 0, t_env: 2000
agent help is true at t: 30, t_env: 2000
agent help is true at t: 0, t_env: 2500
agent help is true at t: 30, t_env: 2500
agent help is true at t: 0, t_env: 3000
agent help is true at t: 30, t_env: 3000
agent help is true at t: 0, t_env: 3500
agent help is true at t: 30, t_env: 3500
agent help is true at t: 0, t_env: 4000
agent help is true at t: 30, t_env: 4000
agent help is true at t: 0, t_env: 4500
agent help is true at t: 30, t_env: 4500
agent help is true at t: 0, t_env: 5000
agent help is true at t: 30, t_env: 5000
agent help is true at t: 0, t_env: 5500
agent help is true at t: 30, t_env: 5500
agent help is true at t: 0, t_env: 6000
agent help is true at t: 30, t_env: 6000
agent help is true at t: 0, t_env: 6500
agent help is true at t: 30, t_env: 6500
agent help is true at t: 0, t_env: 7000
agent help is true at t: 30, t_env: 7000
agent help is true at t: 0, t_env: 7500
agent help is true at t: 30, t_env: 7500
agent help is true at t: 0, t_env: 8000
agent help is true at t: 30, t_env: 8000
agent help is true at t: 0, t_env: 8500
agent help is true at t: 30, t_env: 8500
agent help is true at t: 0, t_env: 9000
agent help is true at t: 30, t_env: 9000
agent help is true at t: 0, t_env: 9500
agent help is true at t: 30, t_env: 9500
agent help is true at t: 0, t_env: 10000
agent help is true at t: 30, t_env: 10000
agent help is true at t: 0, t_env: 10500
agent help is true at t: 30, t_env: 10500
agent help is true at t: 0, t_env: 11000
agent help is true at t: 30, t_env: 11000
agent help is true at t: 0, t_env: 11500
agent help is true at t: 30, t_env: 11500
agent help is true at t: 0, t_env: 12000
agent help is true at t: 30, t_env: 12000
agent help is true at t: 0, t_env: 12500
agent help is true at t: 30, t_env: 12500
agent help is true at t: 0, t_env: 13000
agent help is true at t: 30, t_env: 13000
agent help is true at t: 0, t_env: 13500
agent help is true at t: 30, t_env: 13500
agent help is true at t: 0, t_env: 14000
agent help is true at t: 30, t_env: 14000
agent help is true at t: 0, t_env: 14500
agent help is true at t: 30, t_env: 14500
agent help is true at t: 0, t_env: 15000
agent help is true at t: 30, t_env: 15000
agent help is true at t: 0, t_env: 15500
agent help is true at t: 30, t_env: 15500
agent help is true at t: 0, t_env: 16000
agent help is true at t: 30, t_env: 16000
agent help is true at t: 0, t_env: 16500
agent help is true at t: 30, t_env: 16500
agent help is true at t: 0, t_env: 17000
agent help is true at t: 30, t_env: 17000
agent help is true at t: 0, t_env: 17500
agent help is true at t: 30, t_env: 17500
agent help is true at t: 0, t_env: 18000
agent help is true at t: 30, t_env: 18000
agent help is true at t: 0, t_env: 18500
agent help is true at t: 30, t_env: 18500
agent help is true at t: 0, t_env: 19000
agent help is true at t: 30, t_env: 19000
agent help is true at t: 0, t_env: 19500
agent help is true at t: 30, t_env: 19500
agent help is true at t: 0, t_env: 20000
agent help is true at t: 30, t_env: 20000
agent help is true at t: 0, t_env: 20500
agent help is true at t: 30, t_env: 20500
agent help is true at t: 0, t_env: 21000
agent help is true at t: 30, t_env: 21000
agent help is true at t: 0, t_env: 21500
agent help is true at t: 30, t_env: 21500
agent help is true at t: 0, t_env: 22000
agent help is true at t: 30, t_env: 22000
agent help is true at t: 0, t_env: 22500
agent help is true at t: 30, t_env: 22500
agent help is true at t: 0, t_env: 23000
agent help is true at t: 30, t_env: 23000
agent help is true at t: 0, t_env: 23500
agent help is true at t: 30, t_env: 23500
agent help is true at t: 0, t_env: 24000
agent help is true at t: 30, t_env: 24000
agent help is true at t: 0, t_env: 24500
agent help is true at t: 30, t_env: 24500
[DEBUG 01:15:25] pymarl Stopping Heartbeat
[WARNING 01:15:25] pymarl Aborted after 0:00:22!
Traceback (most recent call last):
  File "/home/ubuntu/PERSONAL-DIR/UOA-NEW/final/human-rware/src/main.py", line 135, in <module>
    ex.run_commandline(params)
  File "/home/ubuntu/miniconda3/envs/epymarl/lib/python3.10/site-packages/sacred/experiment.py", line 313, in run_commandline
    return self.run(
  File "/home/ubuntu/miniconda3/envs/epymarl/lib/python3.10/site-packages/sacred/experiment.py", line 277, in run
    run()
  File "/home/ubuntu/miniconda3/envs/epymarl/lib/python3.10/site-packages/sacred/run.py", line 238, in __call__
    self.result = self.main_function(*args)
  File "/home/ubuntu/miniconda3/envs/epymarl/lib/python3.10/site-packages/sacred/config/captured_function.py", line 42, in captured_function
    result = wrapped(*args, **kwargs)
  File "/home/ubuntu/PERSONAL-DIR/UOA-NEW/final/human-rware/src/main.py", line 44, in my_main
    run(_run, config, _log)
  File "/home/ubuntu/PERSONAL-DIR/UOA-NEW/final/human-rware/src/run.py", line 69, in run
    run_sequential(args=args, logger=logger)
  File "/home/ubuntu/PERSONAL-DIR/UOA-NEW/final/human-rware/src/run.py", line 242, in run_sequential
    learner.train(
  File "/home/ubuntu/PERSONAL-DIR/UOA-NEW/final/human-rware/src/learners/ppo_learner.py", line 93, in train
    agent_outs, _ = self.old_mac.forward(batch, agent_help, t=t)
  File "/home/ubuntu/PERSONAL-DIR/UOA-NEW/final/human-rware/src/controllers/basic_controller.py", line 53, in forward
    agent_outs, self.hidden_states = self.agent(agent_inputs, self.hidden_states)
  File "/home/ubuntu/miniconda3/envs/epymarl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/epymarl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/PERSONAL-DIR/UOA-NEW/final/human-rware/src/modules/agents/rnn_agent.py", line 32, in forward
    q = self.fc2(h)
  File "/home/ubuntu/miniconda3/envs/epymarl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/epymarl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/miniconda3/envs/epymarl/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
